version: '3.8'

services:
  inference-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "7861:7861"
    volumes:
      - huggingface_cache:/root/.cache/huggingface
      - ./api_app.py:/app/api_app.py
      - ./saves:/app/LLaMA-Factory/saves
    environment:
      - CUDA_VISIBLE_DEVICES=-1
      - OMP_NUM_THREADS=4
      - API_KEY=super-secreto-2025  # <--- CAMBIA ESTO
    deploy:
      resources:
        limits:
          memory: 12G
    # --- AQUÍ ESTÁ EL CAMBIO IMPORTANTE ---
    # Agregamos "sentence-transformers scikit-learn"
    command: sh -c "pip install fastapi uvicorn gradio sentence-transformers scikit-learn && python /app/api_app.py"

volumes:
  huggingface_cache:
